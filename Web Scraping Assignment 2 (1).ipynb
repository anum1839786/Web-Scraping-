{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4b4095c",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "465e26ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sony\\AppData\\Local\\Temp\\ipykernel_2436\\1867849868.py:11: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\Sony\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>loaction</th>\n",
       "      <th>Experience_needed</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst / Business Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>METRO Cash &amp; Carry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data analyst/ data analytics / Business analys...</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Delhi /...</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Leading US MNC into Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>PharmEasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Master Data Management Business Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analytics and Interpretation Business Ana...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TA Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Novo Nordisk India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>GAME SHOW NETWORK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hiring For Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Taikee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Business Analyst / Data Analyst</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Chennai,...</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>cliqhr.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Plum</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0                    Data Analyst / Business Analyst   \n",
       "1  data analyst/ data analytics / Business analys...   \n",
       "2                                       Data Analyst   \n",
       "3            Master Data Management Business Analyst   \n",
       "4  Data Analytics and Interpretation Business Ana...   \n",
       "5                                    TA Data Analyst   \n",
       "6                                Senior Data Analyst   \n",
       "7                            Hiring For Data Analyst   \n",
       "8                    Business Analyst / Data Analyst   \n",
       "9                                       Data Analyst   \n",
       "\n",
       "                                            loaction Experience_needed  \\\n",
       "0                                Bangalore/Bengaluru           3-8 Yrs   \n",
       "1  Gurgaon/Gurugram, Bangalore/Bengaluru, Delhi /...           2-7 Yrs   \n",
       "2                                Bangalore/Bengaluru           1-3 Yrs   \n",
       "3                                Bangalore/Bengaluru           6-8 Yrs   \n",
       "4                                Bangalore/Bengaluru           6-8 Yrs   \n",
       "5                                Bangalore/Bengaluru           3-8 Yrs   \n",
       "6                                Bangalore/Bengaluru           2-6 Yrs   \n",
       "7                                Bangalore/Bengaluru           2-5 Yrs   \n",
       "8  Mumbai, Hyderabad/Secunderabad, Pune, Chennai,...           5-8 Yrs   \n",
       "9                                Bangalore/Bengaluru           2-5 Yrs   \n",
       "\n",
       "                    company_name  \n",
       "0             METRO Cash & Carry  \n",
       "1  Leading US MNC into Analytics  \n",
       "2                      PharmEasy  \n",
       "3                      Accenture  \n",
       "4                      Accenture  \n",
       "5             Novo Nordisk India  \n",
       "6              GAME SHOW NETWORK  \n",
       "7                         Taikee  \n",
       "8                     cliqhr.com  \n",
       "9                           Plum  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing labraries to scrape the data \n",
    "\n",
    "import selenium\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium import webdriver \n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Sony\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver\")\n",
    "driver.maximize_window()\n",
    "driver.get(' https://www.naukri.com/')\n",
    "\n",
    "# getting xpath of the attributes require\n",
    "time.sleep(5)\n",
    "search_bar  = driver.find_element(By.XPATH , '//*[@id=\"root\"]/div[2]/div[3]/div/div/div[1]/div/div/div/input').send_keys('Data Analyst')\n",
    "time.sleep(3)\n",
    "location   = driver.find_element(By.XPATH , '//*[@id=\"root\"]/div[2]/div[3]/div/div/div[5]/div/div/div/input').send_keys('Banglore')\n",
    "time.sleep(3)\n",
    "search_click  = driver.find_element(By.XPATH , '//*[@id=\"root\"]/div[2]/div[3]/div/div/div[6]').click()\n",
    "time.sleep(3)\n",
    "job_title  = driver.find_elements(By.XPATH , '//*[@class=\"title fw500 ellipsis\"]')\n",
    "location  = driver.find_elements(By.XPATH , '//ul[@class=\"mt-7\"]//li[3]')\n",
    "years = driver.find_elements(By.XPATH , '//ul[@class=\"mt-7\"]//li[1]')\n",
    "company = driver.find_elements(By.XPATH , '//*[@class=\"subTitle ellipsis fleft\"]')\n",
    "\n",
    "job_title_list=[]\n",
    "location_list  = []\n",
    "years_list=[]\n",
    "company_list=[]\n",
    "for i in  range(10):\n",
    "    job_title_list.append(job_title[i].text)\n",
    "    location_list .append(location[i].text)\n",
    "    years_list.append(years[i].text)\n",
    "    company_list.append(company[i].text)\n",
    "    \n",
    "dataframe = pd.DataFrame ({\n",
    "    'job_title':job_title_list,\n",
    "    'loaction':location_list,\n",
    "    'Experience_needed':years_list,\n",
    "    'company_name':company_list\n",
    "})\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfceac7",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73308bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sony\\AppData\\Local\\Temp\\ipykernel_2436\\2497923856.py:7: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\Sony\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>loaction</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI Technologist Vacancy</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Job Opening with Wipro For Data Scientist posi...</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Chennai, Bang...</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Research Engineer: Deep Learning &amp; Collective ...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Siemens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Research Associate II</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, D...</td>\n",
       "      <td>Genpact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Immediate Joiners</td>\n",
       "      <td>Noida, Mumbai, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Bristlecone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist- AI/ML- R&amp;D</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...</td>\n",
       "      <td>EXL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Urgent Hiring For AI Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...</td>\n",
       "      <td>Ashkom Media India Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>UPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>UPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0                            AI Technologist Vacancy   \n",
       "1  Job Opening with Wipro For Data Scientist posi...   \n",
       "2  Research Engineer: Deep Learning & Collective ...   \n",
       "3                              Research Associate II   \n",
       "4                                     Data Scientist   \n",
       "5                 Data Scientist - Immediate Joiners   \n",
       "6                         Data Scientist- AI/ML- R&D   \n",
       "7                Urgent Hiring For AI Data Scientist   \n",
       "8                                     Data Scientist   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                            loaction  \\\n",
       "0  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...   \n",
       "1  Kolkata, Hyderabad/Secunderabad, Chennai, Bang...   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4  Hyderabad/Secunderabad, Bangalore/Bengaluru, D...   \n",
       "5           Noida, Mumbai, Pune, Bangalore/Bengaluru   \n",
       "6  Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...   \n",
       "7  New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...   \n",
       "8                        Mumbai, Bangalore/Bengaluru   \n",
       "9            Bangalore/Bengaluru, Mumbai (All Areas)   \n",
       "\n",
       "                         company_name  \n",
       "0                               Wipro  \n",
       "1                               Wipro  \n",
       "2                             Siemens  \n",
       "3                             Philips  \n",
       "4                             Genpact  \n",
       "5                         Bristlecone  \n",
       "6                                 EXL  \n",
       "7  Ashkom Media India Private Limited  \n",
       "8                                 UPL  \n",
       "9                                 UPL  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver \n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Sony\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver\")\n",
    "driver.maximize_window()\n",
    "driver.get(' https://www.naukri.com/')\n",
    "\n",
    "# getting xpath of the attributes require\n",
    "time.sleep(5)\n",
    "search_bar  = driver.find_element(By.XPATH , '//*[@id=\"root\"]/div[2]/div[3]/div/div/div[1]/div/div/div/input').send_keys('Data Scientist')\n",
    "time.sleep(3)\n",
    "location   = driver.find_element(By.XPATH , '//*[@id=\"root\"]/div[2]/div[3]/div/div/div[5]/div/div/div/input').send_keys('Banglore')\n",
    "time.sleep(3)\n",
    "search_click  = driver.find_element(By.XPATH , '//*[@id=\"root\"]/div[2]/div[3]/div/div/div[6]').click()\n",
    "time.sleep(3)\n",
    "job_title  = driver.find_elements(By.XPATH , '//*[@class=\"title fw500 ellipsis\"]')\n",
    "location  = driver.find_elements(By.XPATH , '//ul[@class=\"mt-7\"]//li[3]')\n",
    "company = driver.find_elements(By.XPATH , '//*[@class=\"subTitle ellipsis fleft\"]')\n",
    "\n",
    "job_title_list=[]\n",
    "location_list  = []\n",
    "company_list=[]\n",
    "for i in  range(10):\n",
    "    job_title_list.append(job_title[i].text)\n",
    "    location_list .append(location[i].text)\n",
    "    company_list.append(company[i].text)\n",
    "    \n",
    "dataframe = pd.DataFrame ({\n",
    "    'job_title':job_title_list,\n",
    "    'loaction':location_list,\n",
    "    'company_name':company_list\n",
    "})\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7d54a4",
   "metadata": {},
   "source": [
    "Q- 3  : In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "    You have to use the location and salary filter.\n",
    "    You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "    You have to scrape the job-title, job-location, company name, experience required.\n",
    "    The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "125dc1f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sony\\AppData\\Local\\Temp\\ipykernel_2436\\1841904657.py:9: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\Sony\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>loaction</th>\n",
       "      <th>Experience_needed</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Job Opening with Wipro For Data Scientist posi...</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Chennai, Bang...</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Pune, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>SS Supply Chain Solutions Pvt. Ltd. (3SC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist -Machine Learning with Python</td>\n",
       "      <td>Noida, New Delhi, Gurgaon/Gurugram, Delhi / NC...</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "      <td>Genpact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Predictive Analytics</td>\n",
       "      <td>Noida, Mumbai, Chandigarh, Hyderabad/Secundera...</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "      <td>Confidential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Machine learning AI</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Teq Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - MIND Infotech</td>\n",
       "      <td>Noida</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - MIND Infotech</td>\n",
       "      <td>Noida</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Internet Jobs - II</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Jobs Territory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Machine Learning Engineer | Data Engineer | Da...</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru, Delhi / NCR(Sect...</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Tidyquant (OPC) Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist (Python) Immediate Joiners</td>\n",
       "      <td>Noida, Pune, Ahmedabad</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "      <td>Om Software Internet Solutions Private Limited</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0  Job Opening with Wipro For Data Scientist posi...   \n",
       "1                                     Data Scientist   \n",
       "2       Data Scientist -Machine Learning with Python   \n",
       "3              Data Scientist - Predictive Analytics   \n",
       "4               Data Scientist - Machine learning AI   \n",
       "5                     Data Scientist - MIND Infotech   \n",
       "6                     Data Scientist - MIND Infotech   \n",
       "7                Data Scientist - Internet Jobs - II   \n",
       "8  Machine Learning Engineer | Data Engineer | Da...   \n",
       "9          Data Scientist (Python) Immediate Joiners   \n",
       "\n",
       "                                            loaction Experience_needed  \\\n",
       "0  Kolkata, Hyderabad/Secunderabad, Chennai, Bang...           2-7 Yrs   \n",
       "1        Pune, Gurgaon/Gurugram, Bangalore/Bengaluru           2-5 Yrs   \n",
       "2  Noida, New Delhi, Gurgaon/Gurugram, Delhi / NC...           1-4 Yrs   \n",
       "3  Noida, Mumbai, Chandigarh, Hyderabad/Secundera...           1-6 Yrs   \n",
       "4  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...           3-8 Yrs   \n",
       "5                                              Noida           4-8 Yrs   \n",
       "6                                              Noida           4-8 Yrs   \n",
       "7  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...           3-6 Yrs   \n",
       "8  Chennai, Bangalore/Bengaluru, Delhi / NCR(Sect...           1-3 Yrs   \n",
       "9                             Noida, Pune, Ahmedabad           1-4 Yrs   \n",
       "\n",
       "                                     company_name  \n",
       "0                                           Wipro  \n",
       "1       SS Supply Chain Solutions Pvt. Ltd. (3SC)  \n",
       "2                                         Genpact  \n",
       "3                                    Confidential  \n",
       "4                                   Teq Analytics  \n",
       "5        MOTHERSONSUMI INFOTECH & DESIGNS LIMITED  \n",
       "6        MOTHERSONSUMI INFOTECH & DESIGNS LIMITED  \n",
       "7                                  Jobs Territory  \n",
       "8                 Tidyquant (OPC) Private Limited  \n",
       "9  Om Software Internet Solutions Private Limited  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver \n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Sony\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver\")\n",
    "driver.maximize_window()\n",
    "driver.get(' https://www.naukri.com/')\n",
    "\n",
    "# getting xpath of the attributes require\n",
    "time.sleep(5)\n",
    "search_bar  = driver.find_element(By.XPATH , '//*[@id=\"root\"]/div[2]/div[3]/div/div/div[1]/div/div/div/input').send_keys('Data Scientist')\n",
    "time.sleep(3)\n",
    "location   = driver.find_element(By.XPATH , '//*[@id=\"root\"]/div[2]/div[3]/div/div/div[5]/div/div/div/input').send_keys('Banglore')\n",
    "time.sleep(3)\n",
    "search_click  = driver.find_element(By.XPATH , '//*[@id=\"root\"]/div[2]/div[3]/div/div/div[6]').click()\n",
    "time.sleep(3)\n",
    "location  = driver.find_element(By.XPATH, '//*[text()=\"Delhi / NCR\"][1]').click()\n",
    "driver.implicitly_wait(3)\n",
    "salary  = driver.find_element(By.XPATH, '//*[text()=\"3-6 Lakhs\"][1]').click()\n",
    "\n",
    "job_title  = driver.find_elements(By.XPATH , '//*[@class=\"title fw500 ellipsis\"]')\n",
    "location  = driver.find_elements(By.XPATH , '//ul[@class=\"mt-7\"]//li[3]')\n",
    "years = driver.find_elements(By.XPATH , '//ul[@class=\"mt-7\"]//li[1]')\n",
    "company = driver.find_elements(By.XPATH , '//*[@class=\"subTitle ellipsis fleft\"]')\n",
    "\n",
    "job_title_list=[]\n",
    "location_list  = []\n",
    "years_list=[]\n",
    "company_list=[]\n",
    "for i in  range(10):\n",
    "    job_title_list.append(job_title[i].text)\n",
    "    location_list .append(location[i].text)\n",
    "    years_list.append(years[i].text)\n",
    "    company_list.append(company[i].text)\n",
    "    \n",
    "dataframe = pd.DataFrame ({\n",
    "    'job_title':job_title_list,\n",
    "    'loaction':location_list,\n",
    "    'Experience_needed':years_list,\n",
    "    'company_name':company_list\n",
    "})\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fb9fc9",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1121375",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sony\\AppData\\Local\\Temp\\ipykernel_2436\\4096962072.py:7: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\Sony\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Brand_title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ray-Ban</td>\n",
       "      <td>Gradient Round Sunglasses (54)</td>\n",
       "      <td>₹7,419</td>\n",
       "      <td>31% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹359</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹639</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mi</td>\n",
       "      <td>Polarized Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹649</td>\n",
       "      <td>45% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹699</td>\n",
       "      <td>30% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Spectacle Sunglasses (Free Size)</td>\n",
       "      <td>₹359</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>Night Vision, UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹207</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Ray-Ban</td>\n",
       "      <td>Mirrored, UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹4,269</td>\n",
       "      <td>23% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹635</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Ray-Ban</td>\n",
       "      <td>Mirrored Aviator Sunglasses (63)</td>\n",
       "      <td>₹3,549</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                        Brand_title   Price  \\\n",
       "0          Ray-Ban                     Gradient Round Sunglasses (54)  ₹7,419   \n",
       "1   ROZZETTA CRAFT  UV Protection, Gradient Rectangular Sunglasses...    ₹359   \n",
       "2         Fastrack   UV Protection Rectangular Sunglasses (Free Size)    ₹639   \n",
       "3               Mi           Polarized Aviator Sunglasses (Free Size)    ₹649   \n",
       "4         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹699   \n",
       "..             ...                                                ...     ...   \n",
       "95  ROZZETTA CRAFT     UV Protection Spectacle Sunglasses (Free Size)    ₹359   \n",
       "96            SRPM  Night Vision, UV Protection Round Sunglasses (54)    ₹207   \n",
       "97         Ray-Ban    Mirrored, UV Protection Aviator Sunglasses (58)  ₹4,269   \n",
       "98        Fastrack              UV Protection Aviator Sunglasses (57)    ₹635   \n",
       "99         Ray-Ban                   Mirrored Aviator Sunglasses (63)  ₹3,549   \n",
       "\n",
       "   Discount  \n",
       "0   31% off  \n",
       "1   82% off  \n",
       "2   20% off  \n",
       "3   45% off  \n",
       "4   30% off  \n",
       "..      ...  \n",
       "95  82% off  \n",
       "96  79% off  \n",
       "97  23% off  \n",
       "98  20% off  \n",
       "99  52% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver \n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Sony\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver\")\n",
    "driver.maximize_window()\n",
    "driver.get('https://www.flipkart.com/?ef_id=36628718f5911066a1e2e5bcaa236cbb:G:s&s_kwcid=AL!739!10!76484920232329!76485137407154&semcmpid=sem_F1167BY7_Brand_adcenter')\n",
    "cross_button  = driver.find_element(By.XPATH , '/html/body/div[2]/div/div/button').click()\n",
    "\n",
    "search_bar  = driver.find_element(By.XPATH , '//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input').send_keys('Sun glasses')\n",
    "search_sumbit  = driver.find_element(By.XPATH , '//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/button').click()\n",
    "\n",
    "time.sleep(6)\n",
    "count = 1\n",
    "\n",
    "Brand_list = []\n",
    "Brand_title_list = []\n",
    "Price_list = []\n",
    "Discount_list = []\n",
    "\n",
    "\n",
    "for j in range(1,4):  \n",
    "    Brand  = driver.find_elements(By.XPATH , '//*[@class=\"_2WkVRV\"]')\n",
    "    time.sleep(2)\n",
    "    Brand_title = driver.find_elements(By.XPATH , '//*[@class=\"IRpwTa\"]')\n",
    "    time.sleep(2)\n",
    "    Price= driver.find_elements(By.XPATH , '//*[@class=\"_30jeq3\"]')\n",
    "    time.sleep(2)\n",
    "    Discount= driver.find_elements(By.XPATH , '//*[@class=\"_3Ay6Sb\"]')\n",
    "    time.sleep(3)\n",
    "    for i in range(len(Brand)):\n",
    "        Brand_list.append(Brand[i].text)\n",
    "        Brand_title_list.append(Brand_title[i].text)\n",
    "        Price_list.append(Price[i].text)\n",
    "        Discount_list.append(Discount[i].text)\n",
    "        \n",
    "        if count ==100:\n",
    "            break\n",
    "        else:\n",
    "            count+=1\n",
    "    if j==3:\n",
    "        break\n",
    "    else:\n",
    "        driver.get('https://www.flipkart.com/search?q=Sun+glasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page='+str(j+1))\n",
    "df  = pd.DataFrame({\n",
    "    'Brand':Brand_list,\n",
    "    'Brand_title' : Brand_title_list,\n",
    "    'Price':Price_list,\n",
    "    'Discount':Discount_list\n",
    "})\n",
    "df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee6c245",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\n",
    "TSVZAXUHGREPBFGI&marketplace.\n",
    "When you will open the above link you will reach to the below shown webpage .\n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3baf526d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sony\\AppData\\Local\\Temp\\ipykernel_2436\\1285554391.py:8: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\Sony\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Short-Reviews</th>\n",
       "      <th>Full_Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>3</td>\n",
       "      <td>Decent product</td>\n",
       "      <td>Everything u ll like it when u use this iPhone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>iPhone is delivered on time. Display is great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Really very nice... my dad gifted me really I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>I got this phone for good price hence 5 star f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>I genuinely liked it. One of the best mobile p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ratings        Short-Reviews  \\\n",
       "0        5       Simply awesome   \n",
       "1        5  Best in the market!   \n",
       "2        5     Perfect product!   \n",
       "3        5    Worth every penny   \n",
       "4        5            Fabulous!   \n",
       "..     ...                  ...   \n",
       "94       3       Decent product   \n",
       "95       5    Worth every penny   \n",
       "96       5  Best in the market!   \n",
       "97       5       Classy product   \n",
       "98       4            Wonderful   \n",
       "\n",
       "                                         Full_Reviews  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Great iPhone very snappy experience as apple k...  \n",
       "2   Amazing phone with great cameras and better ba...  \n",
       "3   Previously I was using one plus 3t it was a gr...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "94  Everything u ll like it when u use this iPhone...  \n",
       "95  iPhone is delivered on time. Display is great ...  \n",
       "96  Really very nice... my dad gifted me really I ...  \n",
       "97  I got this phone for good price hence 5 star f...  \n",
       "98  I genuinely liked it. One of the best mobile p...  \n",
       "\n",
       "[99 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium import webdriver \n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Sony\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver\")\n",
    "driver.maximize_window()\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART')\n",
    "# all_reviews = driver.find_element(By.XPATH , '//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[9]/div/div/div[5]/div/a/div/span').click()\n",
    "\n",
    "ratings = driver.find_elements(By.XPATH , '//*[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "review  = driver.find_elements(By.XPATH , '//*[@class=\"_2-N8zT\"]')\n",
    "time.sleep(3)\n",
    "count = 1\n",
    "full_review_list = [] \n",
    "rating_list = []\n",
    "review_list = []\n",
    "\n",
    "\n",
    "\n",
    "for k in range(2,15):\n",
    "    ratings = driver.find_elements(By.XPATH , '//*[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    review  = driver.find_elements(By.XPATH , '//*[@class=\"_2-N8zT\"]')\n",
    "    time.sleep(5)\n",
    "    for j in range(3,12):\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        full  = driver.find_element(By.XPATH , '//*[@id=\"container\"]/div/div[3]/div/div/div[2]/div['+str(j)+']/div/div/div/div[2]/div/div/div')\n",
    "#         time.sleep(2)/\n",
    "        rating_list.append(ratings[j-3].text)\n",
    "#         time.sleep(2)\n",
    "        review_list.append(review[j-3].text)\n",
    "#         time.sleep(2)\n",
    "        full_review_list.append(full.text)\n",
    "        count+=1\n",
    "    if k ==13:\n",
    "        break\n",
    "    else:\n",
    "        time.sleep(2)\n",
    "        driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page='+str(k))\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Ratings\":rating_list,\n",
    "    \"Short-Reviews\":review_list,\n",
    "    'Full_Reviews' : full_review_list\n",
    "})\n",
    "df\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d33d17",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com andsearch for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "76a5dc5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sony\\AppData\\Local\\Temp\\ipykernel_2436\\3112130800.py:7: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\Sony\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Brand_title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹499</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cresswell</td>\n",
       "      <td>Cresswell</td>\n",
       "      <td>₹1,499</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Layasa</td>\n",
       "      <td>Layasa</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>₹374</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹283</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ray-Ban</td>\n",
       "      <td>Ray-Ban</td>\n",
       "      <td>₹3,549</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>₹324</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>AISLIN</td>\n",
       "      <td>₹387</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹721</td>\n",
       "      <td>9% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Ray-Ban</td>\n",
       "      <td>Ray-Ban</td>\n",
       "      <td>₹8,429</td>\n",
       "      <td>12% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Brand        Brand_title   Price Discount\n",
       "0              BRUTON             BRUTON    ₹499  85% off\n",
       "1           Cresswell          Cresswell  ₹1,499  57% off\n",
       "2              Layasa             Layasa    ₹399  60% off\n",
       "3        Robbie jones       Robbie jones    ₹374  62% off\n",
       "4              BRUTON             BRUTON    ₹283  78% off\n",
       "..                ...                ...     ...      ...\n",
       "95            Ray-Ban            Ray-Ban  ₹3,549  52% off\n",
       "96  SHAAH COLLECTIONS  SHAAH COLLECTIONS    ₹324  80% off\n",
       "97             AISLIN             AISLIN    ₹387  74% off\n",
       "98           Fastrack           Fastrack    ₹721   9% off\n",
       "99            Ray-Ban            Ray-Ban  ₹8,429  12% off\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver \n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Sony\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver\")\n",
    "driver.maximize_window()\n",
    "driver.get('https://www.flipkart.com/?ef_id=36628718f5911066a1e2e5bcaa236cbb:G:s&s_kwcid=AL!739!10!76484920232329!76485137407154&semcmpid=sem_F1167BY7_Brand_adcenter')\n",
    "cross_button  = driver.find_element(By.XPATH , '/html/body/div[2]/div/div/button').click()\n",
    "\n",
    "search_bar  = driver.find_element(By.XPATH , '//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input').send_keys('Sneakers')\n",
    "search_sumbit  = driver.find_element(By.XPATH , '//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/button').click()\n",
    "\n",
    "time.sleep(6)\n",
    "count = 1\n",
    "\n",
    "Brand_list = []\n",
    "Brand_title_list = []\n",
    "Price_list = []\n",
    "Discount_list = []\n",
    "\n",
    "\n",
    "for j in range(1,4):  \n",
    "    Brand  = driver.find_elements(By.XPATH , '//*[@class=\"_2WkVRV\"]')\n",
    "    time.sleep(2)\n",
    "    Brand_title = driver.find_elements(By.XPATH , '//*[@class=\"_2WkVRV\"]')\n",
    "    time.sleep(2)\n",
    "    Price= driver.find_elements(By.XPATH , '//*[@class=\"_30jeq3\"]')\n",
    "    time.sleep(2)\n",
    "    Discount= driver.find_elements(By.XPATH , '//*[@class=\"_3Ay6Sb\"]')\n",
    "    time.sleep(3)\n",
    "    for i in range(len(Brand)):\n",
    "        Brand_list.append(Brand[i].text)\n",
    "        Brand_title_list.append(Brand_title[i].text)\n",
    "        Price_list.append(Price[i].text)\n",
    "        Discount_list.append(Discount[i].text)\n",
    "        \n",
    "        if count ==100:\n",
    "            break\n",
    "        else:\n",
    "            count+=1\n",
    "    if j==3:\n",
    "        break\n",
    "    else:\n",
    "        driver.get('https://www.flipkart.com/search?q=Sun+glasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page='+str(j+1))\n",
    "df  = pd.DataFrame({\n",
    "    'Brand':Brand_list,\n",
    "    'Brand_title' : Brand_title_list,\n",
    "    'Price':Price_list,\n",
    "    'Discount':Discount_list\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1586aaa",
   "metadata": {},
   "source": [
    "Q7: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 7149 to Rs. 14099 ” , Color filter to “Black”, as shown inthe below image.\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe\n",
    "description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c688356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sony\\AppData\\Local\\Temp\\ipykernel_2156\\3732003004.py:9: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\Sony\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "      <td>Rs. 1349Rs. 5399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Unisex Kent 2.0 IDP Sneakers</td>\n",
       "      <td>Rs. 1799Rs. 2999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Zoom C Pro HC Tennis Shoes</td>\n",
       "      <td>Rs. 5806Rs. 8295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men Max Cushioning Running</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women Pegasus 39 Running Shoes</td>\n",
       "      <td>Rs. 10495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Solid Loafers</td>\n",
       "      <td>Rs. 8990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Formal Loafers</td>\n",
       "      <td>Rs. 8491Rs. 9990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 8991Rs. 9990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Solid Leather Heels</td>\n",
       "      <td>Rs. 8091Rs. 8990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Leather Pumps</td>\n",
       "      <td>Rs. 8099Rs. 8999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand                         Reviews             Price\n",
       "0    Red Tape               Men Walking Shoes  Rs. 1349Rs. 5399\n",
       "1        Puma    Unisex Kent 2.0 IDP Sneakers  Rs. 1799Rs. 2999\n",
       "2        Nike  Men Zoom C Pro HC Tennis Shoes  Rs. 5806Rs. 8295\n",
       "3    Skechers      Men Max Cushioning Running          Rs. 8999\n",
       "4        Nike  Women Pegasus 39 Running Shoes         Rs. 10495\n",
       "..        ...                             ...               ...\n",
       "95  J.FONTINI               Men Solid Loafers          Rs. 8990\n",
       "96       Geox      Men Leather Formal Loafers  Rs. 8491Rs. 9990\n",
       "97       Geox     Men Leather Formal Slip-Ons  Rs. 8991Rs. 9990\n",
       "98       Geox       Women Solid Leather Heels  Rs. 8091Rs. 8990\n",
       "99       Geox             Women Leather Pumps  Rs. 8099Rs. 8999\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium import webdriver \n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Sony\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver\")\n",
    "driver.maximize_window()\n",
    "time.sleep(3)\n",
    "driver.get('https://www.myntra.com/shoes')\n",
    "\n",
    "time.sleep(3)\n",
    "try :\n",
    "    color = driver.find_element(By.XPATH , '//*[text()=\"Black\"]').click()\n",
    "except:\n",
    "    color = driver.find_element(By.XPATH , '//*[text()=\"Black\"][1]').click()\n",
    "time.sleep(3)\n",
    "price_click = driver.find_element(By.XPATH , '//*[@id=\"mountRoot\"]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/span').click()\n",
    "\n",
    "Brand_list = []\n",
    "Price_list = []\n",
    "Review_list = []\n",
    "for j in range(2):\n",
    "    for i in range(1,51):\n",
    "        try : \n",
    "            price = driver.find_element(By.XPATH , '//*[@id=\"desktopSearchResults\"]/div[2]/section/ul/li['+str(i)+']/a/div[2]/div/span[1]')\n",
    "            Price_list.append(price.text)\n",
    "        except StaleElementReferenceException:\n",
    "            time.sleep(3)\n",
    "            price = driver.find_element(By.XPATH , '//*[@id=\"desktopSearchResults\"]/div[2]/section/ul/li['+str(i)+']/a/div[2]/div/span[1]')\n",
    "            Price_list.append(price.text)\n",
    "\n",
    "        try : \n",
    "            Brand = driver.find_element(By.XPATH , '//*[@id=\"desktopSearchResults\"]/div[2]/section/ul/li['+str(i)+']/a/div[2]/h3')\n",
    "            Brand_list.append(Brand.text)\n",
    "        except StaleElementReferenceException:\n",
    "            time.sleep(3)\n",
    "            Brand = driver.find_element(By.XPATH , '//*[@id=\"desktopSearchResults\"]/div[2]/section/ul/li['+str(i)+']/a/div[2]/h3')\n",
    "            Brand_list.append(Brand.text)\n",
    "\n",
    "\n",
    "        try : \n",
    "            review = driver.find_element(By.XPATH , '//*[@id=\"desktopSearchResults\"]/div[2]/section/ul/li['+str(i)+']/a/div[2]/h4[1]')\n",
    "            Review_list.append(review.text)\n",
    "        except StaleElementReferenceException:\n",
    "            time.sleep(3)\n",
    "            review = driver.find_element(By.XPATH , '//*[@id=\"desktopSearchResults\"]/div[2]/section/ul/li['+str(i)+']/a/div[2]/h4[1]')\n",
    "            Review_list.append(review.text)\n",
    "\n",
    "        if i==50:\n",
    "            time.sleep(2)\n",
    "            driver.get('https://www.myntra.com/shoes?f=Color%3ABlack_36454f&p=2&rf=Price%3A7186.0_14124.0_7186.0%20TO%2014124.0')\n",
    "    if j==1:\n",
    "        break\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "df =  pd.DataFrame({\n",
    "    'Brand':Brand_list,\n",
    "    'Reviews':Review_list,\n",
    "    'Price':Price_list\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1feb73",
   "metadata": {},
   "source": [
    "Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price\n",
    "As shown in the below image as the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "465f1eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sony\\AppData\\Local\\Temp\\ipykernel_2156\\3194443007.py:12: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\Sony\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acer Predator Helios 300 11th Gen Intel Core i...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>1,29,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS ROG Strix Scar 15 (2022), 15.6\" (39.62 cm...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>2,33,135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSI Gaming Stealth GS66, Intel 12th Gen. i9-12...</td>\n",
       "      <td>4.6 out of 5 stars</td>\n",
       "      <td>2,99,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo Legion 7 10th Gen Intel Core i9 39.62 c...</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>2,65,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acer Predator Helios 500 Gaming Laptop (11th G...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>3,79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dell G7 7500 10th Gen Intel i9-10885H 15.6 inc...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>2,05,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS ROG Strix Scar 15 (2022), 15.6-inch (39.6...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>2,81,388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Envy 15- 11th Gen Intel Core i9/32GB/1TB SS...</td>\n",
       "      <td>3.3 out of 5 stars</td>\n",
       "      <td>2,02,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Renewed) HP Omen 15-dh0139TX Gaming Laptop (9...</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "      <td>1,38,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title              Rating  \\\n",
       "0  Acer Predator Helios 300 11th Gen Intel Core i...  5.0 out of 5 stars   \n",
       "1  ASUS ROG Strix Scar 15 (2022), 15.6\" (39.62 cm...  4.0 out of 5 stars   \n",
       "2  MSI Gaming Stealth GS66, Intel 12th Gen. i9-12...  4.6 out of 5 stars   \n",
       "3  Lenovo Legion 7 10th Gen Intel Core i9 39.62 c...  4.4 out of 5 stars   \n",
       "4  Acer Predator Helios 500 Gaming Laptop (11th G...  5.0 out of 5 stars   \n",
       "5  Dell G7 7500 10th Gen Intel i9-10885H 15.6 inc...  4.0 out of 5 stars   \n",
       "6  ASUS ROG Strix Scar 15 (2022), 15.6-inch (39.6...  4.0 out of 5 stars   \n",
       "7  HP Envy 15- 11th Gen Intel Core i9/32GB/1TB SS...  3.3 out of 5 stars   \n",
       "8  (Renewed) HP Omen 15-dh0139TX Gaming Laptop (9...  1.0 out of 5 stars   \n",
       "\n",
       "      Price  \n",
       "0  1,29,990  \n",
       "1  2,33,135  \n",
       "2  2,99,990  \n",
       "3  2,65,999  \n",
       "4  3,79,990  \n",
       "5  2,05,990  \n",
       "6  2,81,388  \n",
       "7  2,02,990  \n",
       "8  1,38,000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium import webdriver \n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Sony\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver\")\n",
    "driver.maximize_window()\n",
    "time.sleep(3)\n",
    "driver.get('https://www.amazon.in/')\n",
    "\n",
    "try :\n",
    "    search_bar = driver.find_element(By.XPATH , '//*[@id=\"twotabsearchtextbox\"]').send_keys('Laptops')\n",
    "except NoSuchElementException:\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "search_button = driver.find_element(By.XPATH , '//*[@id=\"nav-search-submit-button\"]').click()\n",
    "\n",
    "intel_core_9 = driver.find_element(By.XPATH , '//*[text()=\"Intel Core i9\"]').click()\n",
    "\n",
    "time.sleep(2)\n",
    "rating_click= driver.find_element(By.XPATH , '//*[@id=\"p_72/1318479031\"]/span/a').click()\n",
    "\n",
    "title = driver.find_elements(By.XPATH , '//*[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "rating = driver.find_elements(By.XPATH , '//*[@class=\"a-row a-size-small\"]//span[@aria-label][1]') \n",
    "price = driver.find_elements(By.XPATH , '//*[@class=\"a-price-whole\"]')\n",
    "\n",
    "title_list = []\n",
    "rating_list = []\n",
    "price_list = []\n",
    "for i in range(len(title)):\n",
    "    title_list.append(title[i].text)\n",
    "    rating_list.append(rating[i].get_attribute('aria-label'))\n",
    "    price_list.append(price[i].text)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Title\":title_list,\n",
    "    \"Rating\":rating_list,\n",
    "    \"Price\":price_list\n",
    "})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e711ad",
   "metadata": {},
   "source": [
    "Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida\n",
    "location. You have to scrape company name, No. of days ago when job was posted, Rating of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02982b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sony\\AppData\\Local\\Temp\\ipykernel_2156\\3137237095.py:10: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\Sony\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Posted_Ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>4.2</td>\n",
       "      <td>11d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hcl Technologies Limited</td>\n",
       "      <td>3.9</td>\n",
       "      <td>13d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EXL Services.com ( I ) Pvt. Ltd.</td>\n",
       "      <td>3.9</td>\n",
       "      <td>24d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Paytm</td>\n",
       "      <td>3.7</td>\n",
       "      <td>6d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Om Software Internet Solutions Private Limited</td>\n",
       "      <td>4.5</td>\n",
       "      <td>14d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Paytm</td>\n",
       "      <td>3.7</td>\n",
       "      <td>24d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>3.3</td>\n",
       "      <td>11d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ashkom Media India Private Limited</td>\n",
       "      <td>3.3</td>\n",
       "      <td>10d ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Company_name Rating Posted_Ago\n",
       "0                   GENPACT India Private Limited    4.0     3d ago\n",
       "1  Optum Global Solutions (India) Private Limited    4.2    11d ago\n",
       "2                   GENPACT India Private Limited    4.0    10d ago\n",
       "3                        Hcl Technologies Limited    3.9    13d ago\n",
       "4                EXL Services.com ( I ) Pvt. Ltd.    3.9    24d ago\n",
       "5                                           Paytm    3.7     6d ago\n",
       "6  Om Software Internet Solutions Private Limited    4.5    14d ago\n",
       "7                                           Paytm    3.7    24d ago\n",
       "8        MOTHERSONSUMI INFOTECH & DESIGNS LIMITED    3.3    11d ago\n",
       "9              Ashkom Media India Private Limited    3.3    10d ago"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium import webdriver \n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import re\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Sony\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver\")\n",
    "driver.maximize_window()\n",
    "time.sleep(3)\n",
    "driver.get('https://www.ambitionbox.com/')\n",
    "\n",
    "search_bar = driver.find_element(By.XPATH , '//*[@class=\"link jobs\"]').click()\n",
    "time.sleep(1)\n",
    "search_click = driver.find_element(By.XPATH , '//*[@id=\"jobs-typeahead\"]/span/input').send_keys('Data scientist')\n",
    "time.sleep(1)\n",
    "sumbit_click = driver.find_element(By.XPATH , '//*[@id=\"jobs\"]/div[2]/div[1]/div[1]/div/div/div/button').click()\n",
    "time.sleep(5)\n",
    "loc_click = driver.find_element(By.XPATH , '//*[@id=\"filters-row\"]/div/div/div[2]/div[1]/p').click()\n",
    "time.sleep(1)\n",
    "input_data1= driver.find_element(By.XPATH , '//*[@id=\"filters-row\"]/div/div/div[2]/div[2]/div/div[2]/input').click()\n",
    "time.sleep(1)\n",
    "input_data= driver.find_element(By.XPATH , '//*[@id=\"filters-row\"]/div/div/div[2]/div[2]/div/div[2]/input').send_keys('Noida')\n",
    "time.sleep(1)\n",
    "choose_data= driver.find_element(By.XPATH , '//*[@id=\"location_Noida\"]').click()\n",
    "\n",
    "time.sleep(4)\n",
    "company  = driver.find_elements(By.XPATH , '//*[@class=\"company body-medium\"]')\n",
    "rating = driver.find_elements(By.XPATH , '//*[@class=\"body-small\"]')\n",
    "\n",
    "posted_days_list = []\n",
    "company_list = []\n",
    "rating_list = []\n",
    "for i in range(len(company)):\n",
    "    posted_days = driver.find_element(By.XPATH , '//*[@id=\"jobsList\"]/div[2]/div[2]/div/div[1]/div['+str(i+1)+']/div[3]/span[@class=\"body-small-l\"][1]') \n",
    "    company_list.append(company[i].text)\n",
    "    rating_list.append(rating[i].text)\n",
    "    posted_days_list.append(posted_days.text)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Company_name\":company_list,\n",
    "    \"Rating\":rating_list,\n",
    "    \"Posted_Ago\":posted_days_list\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beffdfea",
   "metadata": {},
   "source": [
    "Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64b83857",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sony\\AppData\\Local\\Temp\\ipykernel_2156\\3885063429.py:10: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\Sony\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Salary_record</th>\n",
       "      <th>Experience_req</th>\n",
       "      <th>Average_salary</th>\n",
       "      <th>Minimum_salary</th>\n",
       "      <th>Maximum_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>based on 12 salaries</td>\n",
       "      <td>\\n3 yrs exp</td>\n",
       "      <td>₹ 30.2L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 36.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 33 salaries</td>\n",
       "      <td>\\n3-4 yrs exp</td>\n",
       "      <td>₹ 20.6L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 25.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>American Express</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>\\n4 yrs exp</td>\n",
       "      <td>₹ 19.9L</td>\n",
       "      <td>₹ 14.1L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZS</td>\n",
       "      <td>based on 15 salaries</td>\n",
       "      <td>\\n2 yrs exp</td>\n",
       "      <td>₹ 16.7L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 33 salaries</td>\n",
       "      <td>\\n3-4 yrs exp</td>\n",
       "      <td>₹ 16.1L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.6L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Reliance Jio</td>\n",
       "      <td>based on 21 salaries</td>\n",
       "      <td>\\n3-4 yrs exp</td>\n",
       "      <td>₹ 15.7L</td>\n",
       "      <td>₹ 5.6L</td>\n",
       "      <td>₹ 26.2L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>based on 83 salaries</td>\n",
       "      <td>\\n2-4 yrs exp</td>\n",
       "      <td>₹ 15.4L</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 50 salaries</td>\n",
       "      <td>\\n2-4 yrs exp</td>\n",
       "      <td>₹ 14.8L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>based on 57 salaries</td>\n",
       "      <td>\\n2-4 yrs exp</td>\n",
       "      <td>₹ 14.0L</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "      <td>₹ 21.1L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>\\n4 yrs exp</td>\n",
       "      <td>₹ 13.3L</td>\n",
       "      <td>₹ 8.9L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Company_name         Salary_record Experience_req Average_salary  \\\n",
       "0            Walmart  based on 12 salaries    \\n3 yrs exp        ₹ 30.2L   \n",
       "1           Ab Inbev  based on 33 salaries  \\n3-4 yrs exp        ₹ 20.6L   \n",
       "2   American Express  based on 10 salaries    \\n4 yrs exp        ₹ 19.9L   \n",
       "3                 ZS  based on 15 salaries    \\n2 yrs exp        ₹ 16.7L   \n",
       "4              Optum  based on 33 salaries  \\n3-4 yrs exp        ₹ 16.1L   \n",
       "5       Reliance Jio  based on 21 salaries  \\n3-4 yrs exp        ₹ 15.7L   \n",
       "6  Fractal Analytics  based on 83 salaries  \\n2-4 yrs exp        ₹ 15.4L   \n",
       "7    Tiger Analytics  based on 50 salaries  \\n2-4 yrs exp        ₹ 14.8L   \n",
       "8       UnitedHealth  based on 57 salaries  \\n2-4 yrs exp        ₹ 14.0L   \n",
       "9        EXL Service  based on 10 salaries    \\n4 yrs exp        ₹ 13.3L   \n",
       "\n",
       "  Minimum_salary Maximum_salary  \n",
       "0        ₹ 25.0L        ₹ 36.0L  \n",
       "1        ₹ 15.0L        ₹ 25.5L  \n",
       "2        ₹ 14.1L        ₹ 25.0L  \n",
       "3        ₹ 11.0L        ₹ 22.0L  \n",
       "4        ₹ 11.0L        ₹ 22.6L  \n",
       "5         ₹ 5.6L        ₹ 26.2L  \n",
       "6        ₹ 10.0L        ₹ 22.0L  \n",
       "7         ₹ 9.0L        ₹ 20.0L  \n",
       "8         ₹ 8.3L        ₹ 21.1L  \n",
       "9         ₹ 8.9L        ₹ 21.0L  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium import webdriver \n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import re\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Sony\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver\")\n",
    "driver.maximize_window()\n",
    "time.sleep(3)\n",
    "driver.get('https://www.ambitionbox.com/')\n",
    "time.sleep(3)\n",
    "search_bar = driver.find_element(By.XPATH , '//*[@class=\"link salaries\"]').click()\n",
    "time.sleep(1)\n",
    "sumbit_click = driver.find_element(By.XPATH , '//*[@placeholder=\"Search job profiles\"]').click()\n",
    "sumbit_click = driver.find_element(By.XPATH , '//*[@placeholder=\"Search job profiles\"]').send_keys('Data scientist')\n",
    "time.sleep(3)\n",
    "input_data = driver.find_element(By.XPATH , '//*[text()=\"Data Scientist\"]').click()\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "company_list = []\n",
    "salary_record_list = []\n",
    "exp_list = []\n",
    "min_salary_list = []\n",
    "max_salary_list = []\n",
    "average_salary_list = []\n",
    "\n",
    "\n",
    "salary_record = driver.find_elements(By.XPATH , '//*[@class=\"name\"]//span')\n",
    "exp = driver.find_elements(By.XPATH , '//*[@class=\"salaries sbold-list-header\"]')\n",
    "min_salary  =driver.find_elements(By.XPATH , '//*[@class=\"value body-medium\"][1]')\n",
    "max_salary  = driver.find_elements(By.XPATH , '//*[@class=\"value body-medium\"][2]')\n",
    "average_salary = driver.find_elements(By.XPATH , '//*[@class=\"averageCtc\"]')\n",
    "\n",
    "for i in range(10):\n",
    "    company  = driver.find_element(By.XPATH , '//*[@id=\"sal-table\"]/div[2]/div['+str(i+1)+']/div[1]/div/div/div[1]/a')\n",
    "    exp_list.append(exp[i].text[18:])\n",
    "    salary_record_list.append(salary_record[i].text)\n",
    "    company_list.append(company.text)\n",
    "    min_salary_list.append(min_salary[i].text)\n",
    "    max_salary_list.append(max_salary[i].text)\n",
    "    average_salary_list.append(average_salary[i].text)\n",
    "    \n",
    "df = pd.DataFrame({\n",
    "    \"Company_name\":company_list,\n",
    "    \"Salary_record\" : salary_record_list,\n",
    "    \"Experience_req\":exp_list,\n",
    "    \"Average_salary\":average_salary_list,\n",
    "    \"Minimum_salary\":min_salary_list,\n",
    "    \"Maximum_salary\":max_salary_list\n",
    "})\n",
    "df\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833574e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
